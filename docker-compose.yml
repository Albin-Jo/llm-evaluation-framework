version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: deployment/docker/dev/Dockerfile
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    env_file:
      - .env
    depends_on:
      - db
      - redis
    networks:
      - llm-eval-network

  db:
    image: library/postgres:15-alpine
    environment:
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-postgres}
      - POSTGRES_DB=${DB_NAME:-llm_evaluation}
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    ports:
      - "5432:5432"
    networks:
      - llm-eval-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - llm-eval-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  celery_worker:
    build:
      context: .
      dockerfile: deployment/docker/dev/Dockerfile
    command: celery -A app.workers.tasks worker --loglevel=info
    volumes:
      - .:/app
    env_file:
      - .env
    depends_on:
      - redis
      - app
    networks:
      - llm-eval-network

  celery_beat:
    build:
      context: .
      dockerfile: deployment/docker/dev/Dockerfile
    command: celery -A app.workers.tasks beat --loglevel=info
    volumes:
      - .:/app
    env_file:
      - .env
    depends_on:
      - redis
      - app

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.7.0
    ports:
      - "5000:5000"
    command: mlflow server --host 0.0.0.0 --port 5000
    volumes:
      - mlflow_data:/mlflow
    networks:
      - llm-eval-network

networks:
  llm-eval-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  mlflow_data:
