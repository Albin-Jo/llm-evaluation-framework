# LLM Evaluation Framework: Session Context

## Project Overview
The LLM Evaluation Framework is an internal tool for evaluating domain-specific AI agents built with Azure OpenAI. The system allows users to create evaluations, manage datasets, compare agent performance, and generate reports.

## Technical Stack
- **Backend**: FastAPI, Python, SQLAlchemy
- **Frontend**: React, TypeScript, Vite
- **Database**: PostgreSQL
- **Deployment**: Docker

## Current Project Status
- **Current Phase**: Debug and Update evaluation module
- **Last Session Date**: One day ago
- **Last Session Focus**: We have Implemented dataset, prompt Module, evaluation module and agent module
- **Current Focus**: Analyse, debug current implementation and improve the evaluation module. 
- Make sure its following Updated Ragas apis

## Components Status

| Component | Status      | Notes                                              |
|-----------|-------------|----------------------------------------------------|
| Project Structure | Complete    | Basic FastAPI and Angular dashboard setup finished |
| Authentication | Hold        | OIDC integration 80% complete                      |
| Dataset Management | Complete    | All CRUD operations implemented                    |
| Agent Integration |  Started |                          |
| Evaluation Engine | Completed   |                                                    |
| Reports Module | Not Started |                              |
| Frontend Dashboard | Started     | Basic layout complete, components in development   |

## Today's Session Goal
The RAGAS API has changed significantly, so api usages,metric definitions will also need to be updated.
Modifying imports
Updating usage patterns
Replacing outdated metrics with the new ones
In this session, we'll focus on: Analyse, debug, improve current implementation of evaluation module
Focus on all apis, services, models, and repository layer of evluation module.

## Key Considerations
- Include a detailed explanation of the implementation and usage
- Create sample evaluation and test cases so that we can test the apis
- Unit testing should be implemented for critical components
- always make sure to include file name and path reference


## Code References
- Backend Repository Structure: [Link to Gist if applicable]
- Frontend Components: [Link to Gist if applicable]
- API Specifications: [Link to Gist if applicable]

## Immediate Next Steps
1. [First specific task for today's session]
2. [Second specific task for today's session]
3. [Third specific task for today's session] 